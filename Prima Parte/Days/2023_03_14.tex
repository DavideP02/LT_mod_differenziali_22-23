\days{14 marzo 2023}

\osservazione{
    Questo teorema si chiama di ``dipendenza continua'' perché la funzione:\begin{align*}
    N &\longrightarrow \mathscr{C}\left([a,b]; \norma{ \cdot }_{\infty}\right) \\
    \bm{x} &\longmapsto \bm{u}_{(t_0,\bm{x})}(t)
    \end{align*}è continua! Infatti, per $ \bm{x}_k\to \overline{\bm{x}}_0 \in N $ le soluzioni corrispondenti convergono uniformemente.
}
\section{Equazione alle variazioni}
\paragrafo{Domanda}{%
    Ci chiediamo ora se la funzione $ \bm{u}_{(t_0,\bm{x})}(t) $ ha regolarità maggiore rispetto a $ \bm{x} $? Se sì, come si comporta $ \partial_x\bm{u}_{(t_0,\bm{x})}(t) $?
}{}{}
%% BEGIN Equazione alle variazioni
\paragrafo{Equazione alle variazioni}{%
Sia
\[
    \begin{cases}
        {u}'(t)=t\,{u}^{2}\\ 
        {u}(0)={x}
    \end{cases}\qquad u_{(0,x)}(t) = \frac{2x}{2-t^{2}x}, \quad t \in \left(-\sqrt{\frac{2}{x}},\sqrt{\frac{2}{x}}\right)
\]
Ora, interpretando $u_{(0,x)}(t)$ come funzione di due variabili $ t $ e $ x $, analizziamone le derivate parziali:
 \begin{align*}
    \partial_t u_{(0,x)}(t)&=\frac{\partial}{\partial t} u_{(0,x)}(t) = \cdots = t\,u^{2}_{(0,x)}(t)\\[3ex]
    \partial_x u_{(0,x)}(t)&=\frac{\partial}{\partial x} u_{(0,x)}(t) = \frac{\partial}{\partial x}\left(\frac{2x}{2-t^{2}x}\right)\\[2ex] 
    &= \frac{4-\cancel{2t^{2}x}-\cancel{2x(-t^{2})}}{(2-t^{2}x)^{2}}= \frac{4}{(2-t^{2}x)^{2}}
\end{align*}
Notando che la soluzione è $ C^{2} $ possiamo permetterci di calcolare le derivate parziali seconde: \begin{align*}
    \partial_t\partial_x u_{(0,x)}(t) &= \partial_x\partial_t u_{(0,x)}(t) = t \cdot 2u_{(0,x)}(t) \cdot \partial_x u_{(0,x)}(t) 
\end{align*}Valutiamo tutto in $ x = x_0 $, ponendo $ v(t)\coloneqq\partial_x u_{(0,x_0)}(t)$. Si ha che \[
    \frac{d}{dt} v(t)= 2t\,u_{(0,x_0)}(t)\,v(t)
\]ovvero \[
    v'(t)=g(t)\,v(t),\qquad g(t) = 2t\,u_{(0,x_0)}(t)
\]La funzione $ v(t) $ risolve un'equazione \emph{lineare} che si chiama \emph{equazione alle variazioni} dove \[
    g(t)=\frac{\partial}{\partial u}\left[f(t,u)\right]_{u=u_{(0,x_0)}(t)}.
\]
}{daoijfdaoijcdiiididiidiidii}{}
\paragrafo{Generalizzazione}{%
    \begin{itemize}
        \item Sia $ \Omega \subseteq \R^{2} $, $ f:\Omega \to \R $, $ f \in C^{1}(\Omega) $.
        \item Sia $ (t_0,x_0) \in \Omega $ e $ u_{(t_0,x_0)}(t) $ soluzione di \[
            \begin{cases}
                u'(t) = f\left(t,u(t)\right)\\ 
                u(t_0)=x_0
            \end{cases}
        \]e sia $ [a,b] \subseteq I_{\max}  $, dove $ I_{\max}  $ è l'intervallo massimale di $ u_{(t_0,x_0)}(t) $
        \item Se $ N $ è intorno di $ x_0 $: $ \forall\, x \in N $, l'unica soluzione $ u_{(t_0,x)}(t) $ di \[
            \begin{cases}
                u'(t) = f\left(t,u(t)\right)\\ 
                u(t_0)=x
            \end{cases}
        \]è definita su tutto $ [a,b] $
    \end{itemize}Sono nella situazione in cui vale: \begin{align}
            \partial_t u_{(t_0,x)}(t) &= f\left(t,u_{(t_0,x)}(t)\right) &\text{perché è soluzione}\label{eq:1dd}\\ 
            u_{(t_0,x)}(t_0)&=x &\text{è il dato iniziale}\label{eq:2dd}
    \end{align}
    \begin{itemize}
        \item[\eqref{eq:1dd}:] Interpretando la soluzione come funzione anche del dato iniziale $x$, supponiamo che $ u_{(t_0,x)}(t) $ sia derivabile in $ x $ (e questa cosa \emph{non} è stata dimostrata).\\ Allora il secondo membro di \eqref{eq:1dd} è derivabile in $ x $, e dunque anche il primo. Derivando a sinistra e a destra in $ x $ otteniamo: \begin{equation}
            \label{eq:asterisco} \partial_t\partial_x u_{(t_0,x)}(t)=\partial_x f\left(t,u_{(t_0,x)}(t)\right) = \partial_u f\left(t,u_{(t_0,x)}(t)\right) \cdot \partial_x u_{(t_0,x)}(t) 
        \end{equation}
        \item[\eqref{eq:2dd}:] Derivando ambo i membri rispetto a $ x $, ottengo \begin{equation}
            \label{eq:puntino} \partial_x u_{(t_0,x)}(t_0) = 1 
        \end{equation}
    \end{itemize}

    Sia $ v(t)=\partial_x u_{(t_0,x)}(t)  $, allora da \eqref{eq:asterisco} 
    \begin{align*}
        v'(t) =\frac{d}{dt} v(t) &= \partial_u f\left(t, u_{(t_0,x)}(t)\right) \cdot \partial_x u_{(t_0,x)}(t) 
        &= \parentesi{g(t)\coloneqq}{\partial_u f\left(t,u_{(t_0,x)}(t)\right)} \cdot \,v(t),
    \end{align*}mentre da \eqref{eq:puntino} ottengo $ v(t_0)=1 $. 

    Abbiamo trovato che $ v $ risolve il problema di Cauchy lineare: \[
        \begin{cases}
            v'(t)=g(t)\,v(t)\\ 
            v(t_0)=1
        \end{cases}
    \]
}{}{}
%% END
\section{Flusso associato ad una equazione differenziale}
%% BEGIN Flusso associato ad una equazione differenziale
\paragrafo{Definizione del flusso}{%
    Sia $ \bm{f}:\Omega \subseteq \R\times \R^{n}\to \R^{n} $ di classe $ C^{1}(\Omega) $. 

    Sia $ (t_0,\bm{x}_0) \in \Omega$, e sia \[
        \Omega_{0} = \{\bm{x} \in \R^{n}: (t_0,\bm{x}) \in \Omega\}
    \]e sia $ I(\bm{x}) $ l'intervallo massimale della soluzione $ \bm{u}_{(t_0,\bm{x})}(t) $ del problema di Cauchy \[
        \begin{cases}
            \bm{u}'=\bm{f}(t,\bm{u})\\ 
            \bm{u}(t_0)= \bm{x}
        \end{cases}
    \]

    Considero ora l'insieme \[
        E=\{(t,\bm{x}) \in\Omega \colon t \in I(\bm{x}), \bm{x} \in \Omega_{0}\}= I(\bm{x})\times \Omega_0
    \]

    La funzione $ \bm{\Psi} $ definita sotto si chiama \emph{flusso}, e indica dove si trova al tempo $ t $ la soluzione con dato iniziale $ \bm{u}(t_0)=\bm{x} $. \[
        \begin{aligned}
            \bm{\Psi}:E &\longrightarrow \R^{n} \\
    (t,\bm{x}) &\longmapsto \bm{u}_{(t_0,\bm{x})}(t)
        \end{aligned}\qquad \bm{\Psi}_{\bm{x}}(t) \coloneqq \bm{\Psi}(t,\bm{x}) 
    \]
}{}{}
\teorema{}{
    Se $ \bm{f} \in C^{1}(\Omega)$, allora la funzione $ \bm{\Psi} $ è di classe $ C^{1}(E) $.
}
%% END
\paragrafo{Sistemi autonomi}{%
Analizziamo ora il caso dei sistemi autonomi. Prima di tutto
\definizione{Si dice \emph{sistema autonomo} un'equazione differenziale della forma \[
    \bm{x}'=\bm{f}(\bm{x}),\qquad \bm{f}:\Omega \subseteq \R^{n}\to \R^{n}
\]}

    Cosa succede nei sistemi autonomi? Sia\[
        \begin{cases}
            \bm{u}'=\bm{f}(\bm{u})\\ 
            \bm{u}(0)= \bm{x} \in \Omega'
        \end{cases}
    \]con $ \displaystyle f: \Omega = \R\times \Omega' \subseteq \R\times \R^{n}\longrightarrow \R^{n} $, dove: \begin{itemize}
        \item $ \Omega $ è una ``striscia'' di $ \R^{n+1} $, 
        \item $ \Omega' $ è il dominio di $ \bm{f} $.
    \end{itemize} 
    
    Poichè $ \Omega_0 $ non dipende da $ t_0 \leadsto$ fissiamo $ t_0=0 $.

    Preso $ I(\bm{x}) $ intervallo massimale per la soluzione con $ \bm{u}_{(0,\bm{x})} $ e definito l'insieme $ E $ come: \[
        E\coloneq \{(t,\bm{x}): t \in I(\bm{x}), \bm{x} \in \Omega'\}=I(x)\times \Omega'
    \]possiamo scrivere il flusso:
    \begin{align*}
    \bm{\Psi}\colon E &\longrightarrow \R^{n} \\
    (t,\bm{x}) &\longmapsto \bm{u}_{(0,\bm{x})}(t)
    \end{align*}e $\bm{\Psi}_{\bm{x}}(t)\coloneqq \bm{\Psi}(t,\bm{x}) $ è soluzione con $ \bm{u}(0)=\bm{x} $.
}{}{}
\esempio{
    \[
        \begin{cases}
            u'=u(1-x)\\ 
            u(0)=x
        \end{cases}
    \]Si ha che\begin{itemize}
        \item se $ x>1 \colon$ $ I(x) = (\alpha_{x}, + \infty ) $ con $ \alpha_{x}>-\infty  $
        \item se $ x \in [0,1]\colon $ $ I(x) = \R $
        \item se $ x<0 \colon$ $ I(x)=(- \infty, \omega_{x} ) $ con $ \omega_{x}<+ \infty  $
    \end{itemize}
}